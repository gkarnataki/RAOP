{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the project is to predict if the requester on Reddit will receive a Pizza as an act of altruism from one of the other Reddit users. \n",
    "The train and test data files are available in kaggle.com and have been downloaded at the below location before executing this notebook. \n",
    "\n",
    "In this notebook we are going to look at only the non-text field and build a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to add year, month, day and dayofweek fields and drop all text fields as well user-specific fields like giver_username_if_known, requester_username etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(\"/Users/gautamkarnataki/MIDS/train.json\")\n",
    "data['year']=data.apply(lambda x: datetime.utcfromtimestamp(x['unix_timestamp_of_request_utc']).strftime('%Y'), axis=1).astype(int)\n",
    "data['month']=data.apply(lambda x: datetime.utcfromtimestamp(x['unix_timestamp_of_request_utc']).strftime('%m'), axis=1).astype(int)\n",
    "data['day']=data.apply(lambda x: datetime.utcfromtimestamp(x['unix_timestamp_of_request_utc']).strftime('%d'), axis=1).astype(int)\n",
    "data['dayofweek']=data.apply(lambda x: datetime.utcfromtimestamp(x['unix_timestamp_of_request_utc']).weekday(), axis=1).astype(int)\n",
    "data=data.drop(['unix_timestamp_of_request'], axis=1)\n",
    "data=data.drop(['request_id'], axis=1)\n",
    "data=data.drop(['unix_timestamp_of_request_utc'], axis=1)\n",
    "data=data.drop(['request_text_edit_aware'], axis=1)\n",
    "#data=data.drop(['request_title'], axis=1)\n",
    "data=data.drop(['requester_subreddits_at_request'], axis=1)\n",
    "data=data.drop(['requester_username'], axis=1)\n",
    "data=data.drop(['giver_username_if_known'], axis=1)\n",
    "data=data.drop(['requester_user_flair'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cast the non-integer fields to integers. These fields represent days and having days as integers is sufficient for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.requester_account_age_in_days_at_request=data.requester_account_age_in_days_at_request.astype(int)\n",
    "data.requester_account_age_in_days_at_retrieval=data.requester_account_age_in_days_at_retrieval.astype(int)\n",
    "data.requester_days_since_first_post_on_raop_at_retrieval=data.requester_days_since_first_post_on_raop_at_retrieval.astype(int)\n",
    "data.requester_days_since_first_post_on_raop_at_request=data.requester_days_since_first_post_on_raop_at_request.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_downvotes_of_request_at_retrieval              int64\n",
       "number_of_upvotes_of_request_at_retrieval                int64\n",
       "post_was_edited                                          int64\n",
       "request_number_of_comments_at_retrieval                  int64\n",
       "request_text                                            object\n",
       "request_title                                           object\n",
       "requester_account_age_in_days_at_request                 int64\n",
       "requester_account_age_in_days_at_retrieval               int64\n",
       "requester_days_since_first_post_on_raop_at_request       int64\n",
       "requester_days_since_first_post_on_raop_at_retrieval     int64\n",
       "requester_number_of_comments_at_request                  int64\n",
       "requester_number_of_comments_at_retrieval                int64\n",
       "requester_number_of_comments_in_raop_at_request          int64\n",
       "requester_number_of_comments_in_raop_at_retrieval        int64\n",
       "requester_number_of_posts_at_request                     int64\n",
       "requester_number_of_posts_at_retrieval                   int64\n",
       "requester_number_of_posts_on_raop_at_request             int64\n",
       "requester_number_of_posts_on_raop_at_retrieval           int64\n",
       "requester_number_of_subreddits_at_request                int64\n",
       "requester_received_pizza                                  bool\n",
       "requester_upvotes_minus_downvotes_at_request             int64\n",
       "requester_upvotes_minus_downvotes_at_retrieval           int64\n",
       "requester_upvotes_plus_downvotes_at_request              int64\n",
       "requester_upvotes_plus_downvotes_at_retrieval            int64\n",
       "year                                                     int64\n",
       "month                                                    int64\n",
       "day                                                      int64\n",
       "dayofweek                                                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a 80:20 split for training and dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data[\"request_text\"]\n",
    "y = data[\"requester_received_pizza\"]\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=1234)\n",
    "for train_index, dev_index in sss.split(X,y):\n",
    "    break\n",
    "\n",
    "train_data,dev_data = X[train_index],X[dev_index]\n",
    "train_labels,dev_labels = y[train_index],y[dev_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classificaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use basic pre-processing techniques\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def text_preprocessor(s):\n",
    "    message = s.lower()\n",
    "    message = re.sub(r\"\\brequest|\\[|\\]|\\(|\\)|\\$|\\!|\\/|\\.|\\*|\\+|\\&|\\=|\\%|\\:|\\?|\\\"|\\,|\\;|\\@|\\_|\\\\|\\}|\\{|\\||\\~\", \" \", message)\n",
    "    message = re.sub(r\"[0-9]\", \" \", message)\n",
    "    message = re.sub(r\"[-]*\", \"\", message)\n",
    "    message = ' '.join([word[0:20] for word in message.split() if len(word)>3])\n",
    "    return message\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = str_input.split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(clfs):\n",
    "    cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         min_df=5, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,2))\n",
    "    transformer = cv.fit_transform(train_data)\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(transformer,train_labels)\n",
    "    dev_data_trans = cv.transform(dev_data)\n",
    "    y_pred = text_clf.predict(dev_data_trans)\n",
    "    print (\"Accuracy (on dev set): %.4f\" % metrics.accuracy_score(y_true=dev_labels, y_pred=y_pred))\n",
    "    print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "    print('LogLoss {score}'.format(score=log_loss(dev_labels, y_pred)))\n",
    "    predictions.append(text_clf.predict_proba(dev_data_trans))\n",
    "    dev_probabilities=[int(k) for k in dev_labels]\n",
    "    clfs.append(logreg)\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (on dev set): 0.7030\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.85      0.81       305\n",
      "        True       0.35      0.25      0.29        99\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       404\n",
      "   macro avg       0.56      0.55      0.55       404\n",
      "weighted avg       0.67      0.70      0.69       404\n",
      "\n",
      "LogLoss 10.2591335368\n",
      "Accuracy (on dev set): 0.7376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.95      0.85       305\n",
      "        True       0.33      0.07      0.12        99\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       404\n",
      "   macro avg       0.55      0.51      0.48       404\n",
      "weighted avg       0.66      0.74      0.67       404\n",
      "\n",
      "LogLoss 9.06218191145\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "X = data[\"request_text\"]\n",
    "y = data[\"requester_received_pizza\"]\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=1000)\n",
    "for train_index, dev_index in sss.split(X,y):\n",
    "    break\n",
    "\n",
    "train_data,dev_data = X[train_index],X[dev_index]\n",
    "train_labels,dev_labels = y[train_index],y[dev_index]\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         min_df=5, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,1))\n",
    "transformer = cv.fit_transform(train_data)\n",
    "logreg_pizza_text = LogisticRegression()\n",
    "logreg_pizza_text.fit(transformer,train_labels)\n",
    "dev_data_trans = cv.transform(dev_data)\n",
    "y_pred = logreg_pizza_text.predict(dev_data_trans)\n",
    "print (\"Accuracy (on dev set): %.4f\" % metrics.accuracy_score(y_true=dev_labels, y_pred=y_pred))\n",
    "print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "print('LogLoss {score}'.format(score=log_loss(dev_labels, y_pred)))\n",
    "predictions.append(logreg_pizza_text.predict_proba(dev_data_trans))\n",
    "\n",
    "X = data[\"request_title\"]\n",
    "y = data[\"requester_received_pizza\"]\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=1000)\n",
    "for train_index, dev_index in sss.split(X,y):\n",
    "    break\n",
    "    \n",
    "train_data,dev_data = X[train_index],X[dev_index]\n",
    "train_labels,dev_labels = y[train_index],y[dev_index]\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         min_df=5, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,1))\n",
    "transformer = cv.fit_transform(train_data)\n",
    "logreg_pizza_title = LogisticRegression()\n",
    "logreg_pizza_title.fit(transformer,train_labels)\n",
    "dev_data_trans = cv.transform(dev_data)\n",
    "y_pred = logreg_pizza_title.predict(dev_data_trans)\n",
    "print (\"Accuracy (on dev set): %.4f\" % metrics.accuracy_score(y_true=dev_labels, y_pred=y_pred))\n",
    "print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "print('LogLoss {score}'.format(score=log_loss(dev_labels, y_pred)))\n",
    "predictions.append(logreg_pizza_title.predict_proba(dev_data_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamble Score: 0.558724221529\n",
      "Best Weights: [0.25988513 0.69784521]\n"
     ]
    }
   ],
   "source": [
    "def log_loss_func(weights):\n",
    "    ''' scipy minimize will pass the weights as a numpy array '''\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions):\n",
    "            final_prediction += weight*prediction\n",
    "\n",
    "    return log_loss(dev_labels, final_prediction)\n",
    "    \n",
    "#the algorithms need a starting value, right not we chose 0.5 for all weights\n",
    "#its better to choose many random starting points and run minimize a few times\n",
    "starting_values = [0.5]*len(predictions)\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "\n",
    "#our weights are bound between 0 and 1\n",
    "bounds = [(0,1)]*len(predictions)\n",
    "res = minimize(log_loss_func, starting_values, method='Nelder-Mead', bounds=bounds, constraints=cons)\n",
    "\n",
    "print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "print('Best Weights: {weights}'.format(weights=res['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights=res['x']\n",
    "y_pred=[weights[0]*predictions[0][k][1]+weights[1]*predictions[1][k][1] for k in range(len(dev_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=[True if k > 0.5 else False for k in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.98      0.85       305\n",
      "        True       0.30      0.03      0.06        99\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       404\n",
      "   macro avg       0.53      0.50      0.45       404\n",
      "weighted avg       0.64      0.75      0.66       404\n",
      "\n",
      "LogLoss : 8.8056919947\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "print('LogLoss : {score}'.format(score=log_loss(dev_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
