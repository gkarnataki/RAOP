{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the project is to predict if the requester on Reddit will receive a Pizza as an act of altruism from one of the other Reddit users. \n",
    "The train and test data files are available in kaggle.com and have been downloaded at the below location before executing this notebook. \n",
    "\n",
    "In this notebook we are going to look at only the non-text field and build a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to add year, month, day and dayofweek fields and drop all text fields as well user-specific fields like giver_username_if_known, requester_username etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Request Colorado Springs Help Us Please\n",
       "1       [Request] California, No cash and I could use ...\n",
       "2       [Request] Hungry couple in Dundee, Scotland wo...\n",
       "3       [Request] In Canada (Ontario), just got home f...\n",
       "4       [Request] Old friend coming to visit. Would LO...\n",
       "5       [REQUEST] I'll give a two week xbox live code ...\n",
       "6       [Request] Help me give back to my roomies on F...\n",
       "7       random acts of pizza, i have a request, if not...\n",
       "8       [Request] Queensland Australia, Recently moved...\n",
       "9               [REQUEST]We're in need of some om noms...\n",
       "10      [REQUEST] Bummed out in Chicago. Too broke to ...\n",
       "11                   [Request] Would love a pizza tonight\n",
       "12      [REQUEST] Georgia, USA Please help me family o...\n",
       "13                             [Request]  Broke in ATL.  \n",
       "14               [Request] Make my bro in law a believer!\n",
       "15      [Request] I am not a pothead nor a beggar, but...\n",
       "16      [request] Cookeville, TN. My dog recently died...\n",
       "17      [Request] Broke College Kids and Retro Gaming ...\n",
       "18      [Request] Virginia. Girlfriend and I our sick,...\n",
       "19      [Request] Just got back from a job interview t...\n",
       "20      [REQUEST] I can't draw for my life, but I'd lo...\n",
       "21      [REQUEST] Broke College StudENTs stricken with...\n",
       "22                                     [Request] Maryland\n",
       "23             [Request] O-Chem Midterm (before or after)\n",
       "24                  [REQUEST] Will write haiku for pizza!\n",
       "25      [Request] 17-year-old, broke, could use some c...\n",
       "26      [Request] Been sick and unable to work for thr...\n",
       "27      [request] Virginia USA just moved out could re...\n",
       "28      [Request] TEXAS USA! Anybody into video games ...\n",
       "29      [REQUEST] UK - Glasgow. Student having a rough...\n",
       "                              ...                        \n",
       "4010    [Request] Having a bad luck streak. (Des Moine...\n",
       "4011    [Request] College student wanting to surprise ...\n",
       "4012    [REQUEST] Essex Junction, VT - Nearly broke, n...\n",
       "4013    [Request] No manipulative sob story, Id just l...\n",
       "4014    [Request] Haven't eaten since lunch yesterday ...\n",
       "4015    (request) having an absolutely horrible week a...\n",
       "4016               [Request] Need help for friend of mine\n",
       "4017                 [request] hungry student in Michigan\n",
       "4018    [Request] U of Illinois student- No room in th...\n",
       "4019    [REQUEST] St. Louis USA - Needing to feed my c...\n",
       "4020    [Request] Tallahasse, FL - It's been a rough m...\n",
       "4021           [Request] Hungry and broke college student\n",
       "4022    [Request] Just rode my bike home from work in ...\n",
       "4023    [Request] Finally made the decision to leave a...\n",
       "4024    [request] Unemployment check never came, waiti...\n",
       "4025    [Request] My daughter got me hooked on Happy S...\n",
       "4026    [Request] Anyone in need of a logo, flyer, pam...\n",
       "4027    [request] Quebec, Canada.\\nWe want to chill wi...\n",
       "4028    [request] I am a single father just complete m...\n",
       "4029    [Request]Broke after getting screwed over by l...\n",
       "4030    [Request] Passed up free tickets to the Packer...\n",
       "4031    [request] Jacksonville, Florida USA I would lo...\n",
       "4032    [REQUEST] College dudes in Long Beach on sprin...\n",
       "4033    [Request] Morganton, NC Looking for some lunch...\n",
       "4034       [Request] Hungry after work, could use a pizza\n",
       "4035    [REQUEST] Anyone help a recent college grad wh...\n",
       "4036    [Request][USA] Papa Johns is giving away one f...\n",
       "4037    [REQUEST][MI,USA] Day off, would love pizza fo...\n",
       "4038    [Request] Nashua Nh Mother of one hungry 2 yea...\n",
       "4039    [Request] USA WA. Unexpected bill, couldn't go...\n",
       "Name: request_title, Length: 4040, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"/Users/gautamkarnataki/MIDS/train.json\")\n",
    "data['year']=data.apply(lambda x: datetime.utcfromtimestamp(x['unix_timestamp_of_request_utc']).strftime('%Y'), axis=1).astype(int)\n",
    "data['month']=data.apply(lambda x: datetime.utcfromtimestamp(x['unix_timestamp_of_request_utc']).strftime('%m'), axis=1).astype(int)\n",
    "data['day']=data.apply(lambda x: datetime.utcfromtimestamp(x['unix_timestamp_of_request_utc']).strftime('%d'), axis=1).astype(int)\n",
    "data['dayofweek']=data.apply(lambda x: datetime.utcfromtimestamp(x['unix_timestamp_of_request_utc']).weekday(), axis=1).astype(int)\n",
    "data=data.drop(['unix_timestamp_of_request'], axis=1)\n",
    "data=data.drop(['request_id'], axis=1)\n",
    "data=data.drop(['unix_timestamp_of_request_utc'], axis=1)\n",
    "data=data.drop(['request_text'], axis=1)\n",
    "data=data.drop(['request_text_edit_aware'], axis=1)\n",
    "#data=data.drop(['request_title'], axis=1)\n",
    "data=data.drop(['requester_subreddits_at_request'], axis=1)\n",
    "data=data.drop(['requester_username'], axis=1)\n",
    "data=data.drop(['giver_username_if_known'], axis=1)\n",
    "data=data.drop(['requester_user_flair'], axis=1)\n",
    "\n",
    "data['request_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cast the non-integer fields to integers. These fields represent days and having days as integers is sufficient for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.requester_account_age_in_days_at_request=data.requester_account_age_in_days_at_request.astype(int)\n",
    "data.requester_account_age_in_days_at_retrieval=data.requester_account_age_in_days_at_retrieval.astype(int)\n",
    "data.requester_days_since_first_post_on_raop_at_retrieval=data.requester_days_since_first_post_on_raop_at_retrieval.astype(int)\n",
    "data.requester_days_since_first_post_on_raop_at_request=data.requester_days_since_first_post_on_raop_at_request.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification usng Non Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_downvotes_of_request_at_retrieval              int64\n",
       "number_of_upvotes_of_request_at_retrieval                int64\n",
       "post_was_edited                                          int64\n",
       "request_number_of_comments_at_retrieval                  int64\n",
       "request_title                                           object\n",
       "requester_account_age_in_days_at_request                 int64\n",
       "requester_account_age_in_days_at_retrieval               int64\n",
       "requester_days_since_first_post_on_raop_at_request       int64\n",
       "requester_days_since_first_post_on_raop_at_retrieval     int64\n",
       "requester_number_of_comments_at_request                  int64\n",
       "requester_number_of_comments_at_retrieval                int64\n",
       "requester_number_of_comments_in_raop_at_request          int64\n",
       "requester_number_of_comments_in_raop_at_retrieval        int64\n",
       "requester_number_of_posts_at_request                     int64\n",
       "requester_number_of_posts_at_retrieval                   int64\n",
       "requester_number_of_posts_on_raop_at_request             int64\n",
       "requester_number_of_posts_on_raop_at_retrieval           int64\n",
       "requester_number_of_subreddits_at_request                int64\n",
       "requester_upvotes_minus_downvotes_at_request             int64\n",
       "requester_upvotes_minus_downvotes_at_retrieval           int64\n",
       "requester_upvotes_plus_downvotes_at_request              int64\n",
       "requester_upvotes_plus_downvotes_at_retrieval            int64\n",
       "year                                                     int64\n",
       "month                                                    int64\n",
       "day                                                      int64\n",
       "dayofweek                                                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"requester_received_pizza\"]\n",
    "data=data.drop(['requester_received_pizza'], axis=1)\n",
    "X = data\n",
    "\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: [Request] USA WA. Unexpected bill, couldn't go grocery shopping this week.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ae3e5597309e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy of classifier on dev set: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gautamkarnataki/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1284\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gautamkarnataki/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/gautamkarnataki/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/Users/gautamkarnataki/anaconda/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: [Request] USA WA. Unexpected bill, couldn't go grocery shopping this week."
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=1234)\n",
    "for train_index, dev_index in sss.split(X,y):\n",
    "    break\n",
    "\n",
    "train_data,dev_data = X.values[train_index],X.values[dev_index]\n",
    "train_labels,dev_labels = y.values[train_index],y.values[dev_index]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(dev_data)\n",
    "print('Accuracy of classifier on dev set: {:.2f}'.format(clf.score(dev_data, dev_labels)))\n",
    "print('LogLoss : {score}'.format(score=log_loss(dev_labels, y_pred)))\n",
    "print(classification_report(dev_labels, y_pred))\n",
    "predictions.append(clf.predict_proba(dev_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificaton using only text fields (request text and request title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use basic pre-processing techniques\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def text_preprocessor(s):\n",
    "    message = s.lower()\n",
    "    message = re.sub(r\"\\brequest|\\[|\\]|\\(|\\)|\\$|\\!|\\/|\\.|\\*|\\+|\\&|\\=|\\%|\\:|\\?|\\\"|\\,|\\;|\\@|\\_|\\\\|\\}|\\{|\\||\\~\", \" \", message)\n",
    "    message = re.sub(r\"[0-9]\", \" \", message)\n",
    "    message = re.sub(r\"[-]*\", \"\", message)\n",
    "    message = ' '.join([word[0:20] for word in message.split() if len(word)>3])\n",
    "    return message\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = str_input.split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "request_text    Austin, Texas\\n\\nMy two roommates and I are hu...\n",
       "Name: 9, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"/Users/gautamkarnataki/MIDS/train.json\")\n",
    "text = data.loc[data[\"requester_received_pizza\"]==True,[\"request_text\"]]\n",
    "text.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request_text                14.285714\n",
      "requester_received_pizza    14.285714\n",
      "dtype: float64\n",
      "request_text                12.212738\n",
      "requester_received_pizza    12.212738\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "phrase = \"\"\n",
    "\n",
    "text = data.loc[data[\"requester_received_pizza\"]==True,[\"request_text\",\"requester_received_pizza\"]]\n",
    "print text[text[\"request_text\"].str.contains(phrase)==True].count()/len(text) * 100.0\n",
    "\n",
    "text = data.loc[data[\"requester_received_pizza\"]==False,[\"request_text\",\"requester_received_pizza\"]]\n",
    "print text[text[\"request_text\"].str.contains(phrase)==True].count()/len(text) * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (on dev set): 0.7351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.90      0.84       305\n",
      "        True       0.43      0.23      0.30        99\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       404\n",
      "   macro avg       0.60      0.57      0.57       404\n",
      "weighted avg       0.70      0.74      0.71       404\n",
      "\n",
      "LogLoss 9.14770757865\n",
      "(1, 1288)\n",
      "Accuracy (on dev set): 0.7450\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.94      0.85       305\n",
      "        True       0.44      0.14      0.21        99\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       404\n",
      "   macro avg       0.60      0.54      0.53       404\n",
      "weighted avg       0.69      0.75      0.69       404\n",
      "\n",
      "LogLoss 8.80571376591\n",
      "Accuracy (on dev set): 0.7327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.96      0.84       305\n",
      "        True       0.24      0.04      0.07        99\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       404\n",
      "   macro avg       0.49      0.50      0.46       404\n",
      "weighted avg       0.63      0.73      0.65       404\n",
      "\n",
      "LogLoss 9.2331639738\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json(\"/Users/gautamkarnataki/MIDS/train.json\")\n",
    "\n",
    "X = data[\"request_text\"]\n",
    "y = data[\"requester_received_pizza\"]\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=1000)\n",
    "for train_index, dev_index in sss.split(X,y):\n",
    "    break\n",
    "\n",
    "train_data,dev_data = X[train_index],X[dev_index]\n",
    "train_labels,dev_labels = y[train_index],y[dev_index]\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         min_df=10, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,1))\n",
    "transformer = cv.fit_transform(train_data)\n",
    "logreg_pizza_text = LogisticRegression(C=0.5)\n",
    "logreg_pizza_text.fit(transformer,train_labels)\n",
    "dev_data_trans = cv.transform(dev_data)\n",
    "y_pred = logreg_pizza_text.predict(dev_data_trans)\n",
    "print (\"Accuracy (on dev set): %.4f\" % metrics.accuracy_score(y_true=dev_labels, y_pred=y_pred))\n",
    "print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "print('LogLoss {score}'.format(score=log_loss(dev_labels, y_pred)))\n",
    "predictions.append(logreg_pizza_text.predict_proba(dev_data_trans))\n",
    "\n",
    "coeff = logreg_pizza_text.coef_\n",
    "print coeff.shape\n",
    "ind_features = []\n",
    "feat = cv.get_feature_names()\n",
    "for i in range(0,1):\n",
    "    idx = (-coeff[i]).argsort()[:800]\n",
    "    for ind in idx:\n",
    "        ind_features.append(feat[ind])\n",
    "\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         vocabulary=ind_features,\n",
    "                         min_df=10, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,1))\n",
    "transformer = cv.fit_transform(train_data)\n",
    "logreg_pizza_text = LogisticRegression(C=0.5)\n",
    "logreg_pizza_text.fit(transformer,train_labels)\n",
    "dev_data_trans = cv.transform(dev_data)\n",
    "y_pred = logreg_pizza_text.predict(dev_data_trans)\n",
    "print (\"Accuracy (on dev set): %.4f\" % metrics.accuracy_score(y_true=dev_labels, y_pred=y_pred))\n",
    "print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "print('LogLoss {score}'.format(score=log_loss(dev_labels, y_pred)))\n",
    "#predictions.append(logreg_pizza_text.predict_proba(dev_data_trans))\n",
    "\n",
    "X = data[\"request_title\"]\n",
    "y = data[\"requester_received_pizza\"]\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=1000)\n",
    "for train_index, dev_index in sss.split(X,y):\n",
    "    break\n",
    "    \n",
    "train_data,dev_data = X[train_index],X[dev_index]\n",
    "train_labels,dev_labels = y[train_index],y[dev_index]\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         min_df=10, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,1))\n",
    "transformer = cv.fit_transform(train_data)\n",
    "logreg_pizza_title = LogisticRegression(C=1.2)\n",
    "#logreg_pizza_title = RandomForestClassifier(random_state=0)\n",
    "logreg_pizza_title.fit(transformer,train_labels)\n",
    "dev_data_trans = cv.transform(dev_data)\n",
    "y_pred = logreg_pizza_title.predict(dev_data_trans)\n",
    "print (\"Accuracy (on dev set): %.4f\" % metrics.accuracy_score(y_true=dev_labels, y_pred=y_pred))\n",
    "print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "print('LogLoss {score}'.format(score=log_loss(dev_labels, y_pred)))\n",
    "predictions.append(logreg_pizza_title.predict_proba(dev_data_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamble Score: 0.547287548424\n",
      "Best Weights: [0.14580708 0.28254264 0.57165029]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      1.00      0.86       305\n",
      "        True       0.00      0.00      0.00        99\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       404\n",
      "   macro avg       0.38      0.50      0.43       404\n",
      "weighted avg       0.57      0.75      0.65       404\n",
      "\n",
      "LogLoss : 8.46371005717\n"
     ]
    }
   ],
   "source": [
    "def log_loss_func(weights):\n",
    "    ''' scipy minimize will pass the weights as a numpy array '''\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions):\n",
    "            final_prediction += weight*prediction\n",
    "\n",
    "    return log_loss(dev_labels, final_prediction)\n",
    "    \n",
    "#the algorithms need a starting value, right not we chose 0.5 for all weights\n",
    "#its better to choose many random starting points and run minimize a few times\n",
    "starting_values = [0.3333]*len(predictions)\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "\n",
    "#our weights are bound between 0 and 1\n",
    "bounds = [(0,1)]*len(predictions)\n",
    "res = minimize(log_loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "print('Best Weights: {weights}'.format(weights=res['x']))\n",
    "\n",
    "weights=res['x']\n",
    "y_pred=[weights[0]*predictions[0][k][1]+weights[1]*predictions[1][k][1] for k in range(len(dev_data))]\n",
    "y_pred=[True if k > 0.5 else False for k in y_pred]\n",
    "print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "print('LogLoss : {score}'.format(score=log_loss(dev_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal(classifier, parameters, train_data, train_labels, param_label):\n",
    "        # Set the scoring parameter to F1 as this is the score we're basing our accuracy on.\n",
    "        clf = GridSearchCV(classifier, parameters, scoring='f1_weighted')\n",
    "        clf.fit(train_data, train_labels)\n",
    "        print \"\\nBest value of {0} = {1} [Mean F1-score = {2}]\".format(param_label, clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gautamkarnataki/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/gautamkarnataki/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best value of C = {'C': 0.5} [Mean F1-score = 0.688603082912]\n"
     ]
    }
   ],
   "source": [
    "X = data[\"request_text\"]\n",
    "y = data[\"requester_received_pizza\"]\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=1000)\n",
    "for train_index, dev_index in sss.split(X,y):\n",
    "    break\n",
    "\n",
    "train_data,dev_data = X[train_index],X[dev_index]\n",
    "train_labels,dev_labels = y[train_index],y[dev_index]\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         min_df=10, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,1))\n",
    "transformer = cv.fit_transform(train_data)\n",
    "logreg_pizza_text = LogisticRegression(C=1.0, class_weight='balanced')\n",
    "#logreg_pizza_text = RandomForestClassifier(random_state=0)\n",
    "logreg_pizza_text.fit(transformer,train_labels)\n",
    "dev_data_trans = cv.transform(dev_data)\n",
    "y_pred = logreg_pizza_text.predict(dev_data_trans)\n",
    "\n",
    "parameters = {'C': [0.001,0.01,0.1,0.5,0.75,1.0,1.1,1.2]}\n",
    "find_optimal(LogisticRegression(),parameters,transformer,train_labels,'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best value of C = {'C': 1.2} [Mean F1-score = 0.663180592487]\n"
     ]
    }
   ],
   "source": [
    "X = data[\"request_title\"]\n",
    "y = data[\"requester_received_pizza\"]\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=1000)\n",
    "for train_index, dev_index in sss.split(X,y):\n",
    "    break\n",
    "    \n",
    "train_data,dev_data = X[train_index],X[dev_index]\n",
    "train_labels,dev_labels = y[train_index],y[dev_index]\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         min_df=10, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,1))\n",
    "transformer = cv.fit_transform(train_data)\n",
    "logreg_pizza_title = LogisticRegression()\n",
    "#logreg_pizza_title = RandomForestClassifier(random_state=0)\n",
    "logreg_pizza_title.fit(transformer,train_labels)\n",
    "dev_data_trans = cv.transform(dev_data)\n",
    "y_pred = logreg_pizza_title.predict(dev_data_trans)\n",
    "\n",
    "parameters = {'C': [0.001,0.01,0.1,0.5,0.75,1.0,1.1,1.2]}\n",
    "find_optimal(LogisticRegression(),parameters,transformer,train_labels,'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with an even split of positive and negative cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(\"/Users/gautamkarnataki/MIDS/train.json\")\n",
    "all_data = data[data[\"requester_received_pizza\"]==True].iloc[0:1000]\n",
    "all_data = all_data.append(data[data[\"requester_received_pizza\"]==False].iloc[0:1000])\n",
    "data = all_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, dev_data = train_test_split(data, test_size=0.2)\n",
    "train_labels = train_data[\"requester_received_pizza\"]\n",
    "dev_labels = dev_data[\"requester_received_pizza\"]\n",
    "train_data = train_data['request_text']\n",
    "dev_data = dev_data['request_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (on dev set): 0.5915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.60      0.60       204\n",
      "        True       0.58      0.58      0.58       195\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       399\n",
      "   macro avg       0.59      0.59      0.59       399\n",
      "weighted avg       0.59      0.59      0.59       399\n",
      "\n",
      "LogLoss 14.1099902741\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english',\n",
    "                         preprocessor=text_preprocessor,\n",
    "                         lowercase=True,\n",
    "                         tokenizer=stemming_tokenizer,\n",
    "                         min_df=5, \n",
    "                         max_df=0.2, \n",
    "                         ngram_range=(1,1))\n",
    "transformer = cv.fit_transform(train_data)\n",
    "logreg_pizza_title = LogisticRegression(C=0.5)\n",
    "logreg_pizza_title.fit(transformer,train_labels)\n",
    "dev_data_trans = cv.transform(dev_data)\n",
    "y_pred = logreg_pizza_title.predict(dev_data_trans)\n",
    "print (\"Accuracy (on dev set): %.4f\" % metrics.accuracy_score(y_true=dev_labels, y_pred=y_pred))\n",
    "print (metrics.classification_report(y_true=dev_labels, y_pred=y_pred))\n",
    "print('LogLoss {score}'.format(score=log_loss(dev_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
